{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport os\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, BatchNormalization, Dropout, Dense\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nimport tensorflow as tf","metadata":{},"execution_count":1,"outputs":[{"name":"stderr","output_type":"stream","text":"2022-11-11 15:46:24.150740: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"}]},{"cell_type":"code","source":"# variables for image dimensions \n\nimage_width, image_height = 128,128\n\nimage_size = (image_width, image_height)\nchannels = (3,)\n\nimg_input = image_size + channels","metadata":{},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# classifying dogs and cats \n\nfilenames=os.listdir(\"train/\")\n\n\ncategories=[]\nfor img in filenames:\n    category=img.split('.')[0]\n    if category=='dog':\n        categories.append(1)\n    else:\n        categories.append(0)\ndf=pd.DataFrame({\n    'filename':filenames,\n    'category':categories\n})","metadata":{},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df[\"category\"] = df[\"category\"].replace({0:'cat',1:'dog'})\ntrain_df,validate_df = train_test_split(df,test_size=0.20,\n  random_state=42)\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)\ntotal_train=train_df.shape[0]\ntotal_validate=validate_df.shape[0]\nbatch_size=15","metadata":{},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Callbacks and lr\n\n# earlystop = EarlyStopping(patience = 10)\nlearning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',patience = 2,verbose = 1,factor = 0.5,min_lr = 0.00001)\ncallbacks = [learning_rate_reduction]","metadata":{},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# datagens made for training and testing of the program\n\ntrain_datagen = ImageDataGenerator(rotation_range=15,\n                                rescale=1./255,\n                                shear_range=0.1,\n                                zoom_range=0.2,\n                                horizontal_flip=True,\n                                width_shift_range=0.1,\n                                height_shift_range=0.1\n                                )\ntrain_generator = train_datagen.flow_from_dataframe(train_df,\n                                                 \"train/\",x_col='filename',y_col='category',\n                                                 target_size=image_size,\n                                                 class_mode='categorical',\n                                                 batch_size=batch_size,validate_filenames=False,)\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\nvalidation_generator = validation_datagen.flow_from_dataframe(validate_df,\n                                                            \"train/\", \n                                                            x_col='filename',\n                                                            y_col='category',\n                                                            target_size=image_size,\n                                                            class_mode='categorical',\n                                                            batch_size=batch_size,validate_filenames=False,)\ntest_datagen = ImageDataGenerator(rotation_range=15,\n                                rescale=1./255,\n                                shear_range=0.1,\n                                zoom_range=0.2,\n                                horizontal_flip=True,\n                                width_shift_range=0.1,\n                                height_shift_range=0.1)\ntest_generator = train_datagen.flow_from_dataframe(train_df,\n                                                 \"test/\",x_col='filename',y_col='category',\n                                                 target_size=image_size,\n                                                 class_mode='categorical',\n                                                 batch_size=batch_size,validate_filenames=False,)","metadata":{},"execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":"Found 21092 non-validated image filenames belonging to 1 classes.\n\nFound 5274 non-validated image filenames belonging to 1 classes.\n\nFound 21092 non-validated image filenames belonging to 1 classes.\n"}]},{"cell_type":"code","source":"#Model Creation\n\ndef create_model():\n    \"\"\"\n    input shape - 128, 128, 3\n    input is passed to 3 convolutional layers\n    \"\"\"\n    model = tf.keras.models.Sequential([Conv2D(32, (3, 3), activation = 'relu', input_shape = img_input),\n                                      MaxPool2D(2,2),\n                                     \n                                      Conv2D(64, (3, 3), activation = 'relu'),\n                                      MaxPool2D(2,2)\n                                    \n                                      Conv2D(128, (3, 3), activation = 'relu'),\n                                      MaxPool2D(2,2),\n                                      \n                                      Flatten(),\n                                      BatchNormalization(),\n                                      Dropout(0.5),  \n                                      Dense(2, activation='relu', dtype=\"float32\")])\n    model.compile(loss='categorical_crossentropy',\n      optimizer='rmsprop',metrics=['accuracy'])\n\n    return model","metadata":{},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = create_model()","metadata":{},"execution_count":8,"outputs":[{"name":"stderr","output_type":"stream","text":"2022-11-11 15:46:24.907214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n\n2022-11-11 15:46:24.926574: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n\n2022-11-11 15:46:24.926585: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n\nSkipping registering GPU devices...\n\n2022-11-11 15:46:24.926864: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"}]},{"cell_type":"code","source":"model.summary()","metadata":{},"execution_count":9,"outputs":[{"name":"stdout","output_type":"stream","text":"Model: \"sequential\"\n\n_________________________________________________________________\n\n Layer (type)                Output Shape              Param #   \n\n=================================================================\n\n conv2d (Conv2D)             (None, 126, 126, 32)      896       \n\n                                                                 \n\n max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n\n )                                                               \n\n                                                                 \n\n conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n\n                                                                 \n\n max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n\n 2D)                                                             \n\n                                                                 \n\n conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n\n                                                                 \n\n max_pooling2d_2 (MaxPooling  (None, 14, 14, 128)      0         \n\n 2D)                                                             \n\n                                                                 \n\n flatten (Flatten)           (None, 25088)             0         \n\n                                                                 \n\n batch_normalization (BatchN  (None, 25088)            100352    \n\n ormalization)                                                   \n\n                                                                 \n\n dropout (Dropout)           (None, 25088)             0         \n\n                                                                 \n\n dense (Dense)               (None, 2)                 50178     \n\n                                                                 \n\n=================================================================\n\nTotal params: 243,778\n\nTrainable params: 193,602\n\nNon-trainable params: 50,176\n\n_________________________________________________________________\n"}]},{"cell_type":"code","source":"# running the model, for 10 epoch and 50 steps per epoch\n\nepochs=10\nhistory = model.fit(\n    train_generator, \n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate//batch_size,\n    steps_per_epoch=50,\n    callbacks=callbacks\n)","metadata":{},"execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1/10\n\n49/50 [============================>.] - ETA: 0s - loss: nan - accuracy: 0.9918WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n\n50/50 [==============================] - 8s 158ms/step - loss: nan - accuracy: 0.9920 - val_loss: nan - val_accuracy: 1.0000 - lr: 0.0010\n\nEpoch 2/10\n\n49/50 [============================>.] - ETA: 0s - loss: nan - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n\n50/50 [==============================] - 8s 169ms/step - loss: nan - accuracy: 1.0000 - val_loss: nan - val_accuracy: 1.0000 - lr: 0.0010\n\nEpoch 3/10\n\n50/50 [==============================] - ETA: 0s - loss: nan - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n\n50/50 [==============================] - 9s 174ms/step - loss: nan - accuracy: 1.0000 - val_loss: nan - val_accuracy: 1.0000 - lr: 0.0010\n\nEpoch 4/10\n\n50/50 [==============================] - ETA: 0s - loss: nan - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n\n50/50 [==============================] - 8s 170ms/step - loss: nan - accuracy: 1.0000 - val_loss: nan - val_accuracy: 1.0000 - lr: 0.0010\n\nEpoch 5/10\n\n49/50 [============================>.] - ETA: 0s - loss: nan - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n\n50/50 [==============================] - 8s 171ms/step - loss: nan - accuracy: 1.0000 - val_loss: nan - val_accuracy: 1.0000 - lr: 0.0010\n\nEpoch 6/10\n\n49/50 [============================>.] - ETA: 0s - loss: nan - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n\n50/50 [==============================] - 9s 175ms/step - loss: nan - accuracy: 1.0000 - val_loss: nan - val_accuracy: 1.0000 - lr: 0.0010\n\nEpoch 7/10\n\n50/50 [==============================] - ETA: 0s - loss: nan - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n\n50/50 [==============================] - 8s 164ms/step - loss: nan - accuracy: 1.0000 - val_loss: nan - val_accuracy: 1.0000 - lr: 0.0010\n\nEpoch 8/10\n\n50/50 [==============================] - ETA: 0s - loss: nan - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n\n50/50 [==============================] - 8s 168ms/step - loss: nan - accuracy: 1.0000 - val_loss: nan - val_accuracy: 1.0000 - lr: 0.0010\n\nEpoch 9/10\n\n49/50 [============================>.] - ETA: 0s - loss: nan - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n\n50/50 [==============================] - 9s 173ms/step - loss: nan - accuracy: 1.0000 - val_loss: nan - val_accuracy: 1.0000 - lr: 0.0010\n\nEpoch 10/10\n\n50/50 [==============================] - ETA: 0s - loss: nan - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n\n50/50 [==============================] - 9s 172ms/step - loss: nan - accuracy: 1.0000 - val_loss: nan - val_accuracy: 1.0000 - lr: 0.0010\n"}]}]}